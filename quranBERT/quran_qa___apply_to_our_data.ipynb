{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_-hm7ZcPKQ"
      },
      "source": [
        "## installing packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTq7lHJbYu7K",
        "outputId": "db177518-1dec-4000-adcd-e3592f1e29d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 45.2 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 39.0 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 35.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, responses, huggingface-hub, transformers, farasapy, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 farasapy-0.0.14 frozenlist-1.3.0 fsspec-2022.2.0 huggingface-hub-0.4.0 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers farasapy datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm0A3qBlvpb1"
      },
      "outputs": [],
      "source": [
        "# !pip install arabic-reshaper python-bidi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YiJoxJnvuai",
        "outputId": "2f08f770-a7ed-4855-8ccb-ac4a545eb973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 636 kB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "Successfully installed pyyaml-5.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml==5.4.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KqQcHBhREAP"
      },
      "source": [
        "## Download ARCD & Arabic SQUAD & AQAAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhATktPBTOvq",
        "outputId": "8573ac5a-ec7e-440b-ae07-10811ba1f51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-28 11:01:28--  https://raw.githubusercontent.com/husseinmozannar/SOQAL/master/data/arcd.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1942371 (1.9M) [text/plain]\n",
            "Saving to: ‘arcd.json’\n",
            "\n",
            "arcd.json           100%[===================>]   1.85M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-03-28 11:01:28 (33.7 MB/s) - ‘arcd.json’ saved [1942371/1942371]\n",
            "\n",
            "--2022-03-28 11:01:28--  https://raw.githubusercontent.com/husseinmozannar/SOQAL/master/data/Arabic-SQuAD.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51323713 (49M) [text/plain]\n",
            "Saving to: ‘Arabic-SQuAD.json’\n",
            "\n",
            "Arabic-SQuAD.json   100%[===================>]  48.95M   204MB/s    in 0.2s    \n",
            "\n",
            "2022-03-28 11:01:29 (204 MB/s) - ‘Arabic-SQuAD.json’ saved [51323713/51323713]\n",
            "\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.63.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.25.11)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6\n",
            "To: /content/AAQAD.json\n",
            "100% 9.94M/9.94M [00:00<00:00, 118MB/s]\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/husseinmozannar/SOQAL/master/data/arcd.json\n",
        "!wget https://raw.githubusercontent.com/husseinmozannar/SOQAL/master/data/Arabic-SQuAD.json\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1jhUmWb9eHVATqhrWKAXxSE2gqJ53-wk6 -O AAQAD.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GB1IH8RbFI"
      },
      "source": [
        "## Loading ARCD & Arabic SQUAD & AQAAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUCzwcdORVch"
      },
      "outputs": [],
      "source": [
        "arcd_path = \"/content/arcd.json\"\n",
        "ar_squad_path= \"/content/Arabic-SQuAD.json\"\n",
        "ar_AAQAD_path= \"/content/AAQAD.json\"\n",
        "\n",
        "import json \n",
        "def read_data(datapath):\n",
        "  with open(datapath ,'rb') as fp:\n",
        "    data = json.load(fp)\n",
        "  return data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcJ4WH2YR4CW"
      },
      "outputs": [],
      "source": [
        "ar_squad_data=read_data(ar_squad_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqkcE6IrR7IT",
        "outputId": "037d1494-3b46-48bc-c3aa-87edf2d7ec26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "السنسكريتية هي اللغة المقدسة الأولى لأي دين؟ [{'text': 'للهندوسية', 'answer_start': 134}]\n",
            "للهندوسية\n"
          ]
        }
      ],
      "source": [
        "sample =ar_squad_data['data'][10]['paragraphs'][0]\n",
        "text = sample['context']\n",
        "q = sample['qas'][0]['question']\n",
        "answers= sample['qas'][0]['answers']\n",
        "print(q , answers)\n",
        "answer_start= answers[0]['answer_start']\n",
        "answer_end =answer_start+ len(answers[0]['text'])\n",
        "print(text[answer_start:answer_end])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGcr5jPXR-Yj",
        "outputId": "55bddd46-a02e-4697-dc78-713be9d6d551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'يعتمد ASCII أساس ا على الأبجدية الإنجليزية ، ويقوم بترميز 128 حرف ا محدد ا في أعداد صحيحة من سبعة أجزاء كما هو موضح في مخطط ASCII على اليمين . الأحرف المشفرة هي الأرقام من 0 إلى 9 ، والأحرف الصغيرة ا إلى ز ، والأحرف الكبيرة A إلى Z ، ورموز الترقيم الأساسية ، ورموز التحكم التي نشأت مع أجهزة تيليتيبي ، ومساحة . على سبيل المثال ، سيصبح الحرف الصغير ج 1101010 والعشري 106 . تتضمن ASCII تعريفات لـ 128 حرف ا 33 حرف ا تحكم ا غير الطباعة العديد منها الآن قديمة تؤثر على كيفية معالجة النص والمساحة و 95 حرف ا قابلا للطباعة ، بما في ذلك المساحة التي ي عتبر رسم ا غير مرئي 223 .',\n",
              " 'qas': [{'answers': [{'answer_start': 23, 'text': 'الأبجدية الإنجليزية'}],\n",
              "   'id': '570bce516b8089140040fa42',\n",
              "   'question': 'ما هو ASCII على أساس؟'},\n",
              "  {'answers': [{'answer_start': 58, 'text': '128 حرف ا محدد'}],\n",
              "   'id': '570bce516b8089140040fa43',\n",
              "   'question': 'كم شخصيات محددة موجودة في كود ASCII؟'},\n",
              "  {'answers': [{'answer_start': 405, 'text': '33 حرف ا تحكم ا غير الطباعة'}],\n",
              "   'id': '570bce516b8089140040fa44',\n",
              "   'question': 'كم عدد أحرف التحكم غير الطباعة؟'},\n",
              "  {'answers': [{'answer_start': 494, 'text': '95 حرف ا قابلا للطباعة'}],\n",
              "   'id': '570bce516b8089140040fa45',\n",
              "   'question': 'كم شخصيات قابلة للطباعة؟'},\n",
              "  {'answers': [{'answer_start': 550, 'text': 'رسم ا غير مرئي 223'}],\n",
              "   'id': '570bce516b8089140040fa46',\n",
              "   'question': 'ما هو الفضاء المعروف أيضا باسم ماذا؟'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ar_squad_data['data'][0]['paragraphs'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgc1SP9KSBOb"
      },
      "outputs": [],
      "source": [
        "squad_data =[]\n",
        "for sample in ar_squad_data['data']:\n",
        "  paragraphs = sample['paragraphs']\n",
        "  for passage in paragraphs:\n",
        "    text =passage['context']\n",
        "    for qas in passage['qas']:\n",
        "      if len(qas['answers'])<1: \n",
        "        print(qas['answers']['text'])\n",
        "        continue\n",
        "      #for answer in qas['answers']:\n",
        "      squad_data.append(\n",
        "          {\n",
        "              'passage':text,\n",
        "              'question':qas['question'],\n",
        "              # 'answers':qas['answers']\n",
        "              'answers': [{\n",
        "              'text':qas['answers'][0]['text'],\n",
        "              'start_char':qas['answers'][0]['answer_start']\n",
        "          }]\n",
        "          }\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayhSiecuZHR0"
      },
      "outputs": [],
      "source": [
        "squad_data[1000]\n",
        "squad_data_part =[x for x in squad_data if \"محمد\" in x['passage'] ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rkCj4qESFD6",
        "outputId": "05f9c37f-3047-451d-c3bb-f48f16102164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48344\n"
          ]
        }
      ],
      "source": [
        "print(len(squad_data))\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# squad_data_part , test_data = train_test_split(squad_data , test_size= 0.6)\n",
        "import random \n",
        "squad_data_part = random.sample(squad_data , 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v47YmA6vNmFk",
        "outputId": "d43bf2b8-26e3-45fc-c1d1-3ff12e0ba445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': [{'start_char': 109, 'text': 'بفقدان السمع'}],\n",
              " 'passage': 'من الجيل الخامس من يبود ، طرحت شركة اببلي حد ا للحجم القابل للتكوين من قبل المستخدم استجابة للمخاوف المتعلقة بفقدان السمع . أبلغ المستخدمون أنه في الجيل السادس من يبود ، الحد الأقصى لمستوى خرج الصوت محدد بـ 100 ديسيبل في أسواق الاتحاد الأوروبي . اضطرت شركة اببلي في السابق إلى إزالة أجهزة يبود من الأرفف في فرنسا لتجاوزها الحد القانوني . ومع ذلك ، أبلغ المستخدمون الذين اشتروا جهاز ا جديد ا من الجيل السادس من أجهزة يبود في أواخر عام 2013 عن خيار جديد سمح لهم بتعطيل حد حجم الاتحاد الأوروبي . لقد قيل أن أجهزة يبود الجديدة هذه مزودة ببرنامج محدث يسمح بهذا التغيير . إلا أن أجهزة يبود القديمة من الجيل السادس غير قادرة على التحديث إلى إصدار البرنامج هذا .',\n",
              " 'question': 'ما هو نوع المسألة الحسية التي كانت مصدر قلق قبل إصدار iPod 5s Gen؟'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print(len(squad_data_part))\n",
        "squad_data_part[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xZPcizASIK9"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# squad_datadf = pd.DataFrame(train_data).sample(frac=0.4).reset_index()\n",
        "# #valdatadf = pd.DataFrame(test_data).sample(frac=0.02).reset_index()\n",
        "# testdatadf =pd.DataFrame(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0z5mZsRSLKj"
      },
      "outputs": [],
      "source": [
        "# squad_datadf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xdBsbUtSPaw"
      },
      "outputs": [],
      "source": [
        "#squad_datadf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GV5IYSAZ5r7"
      },
      "outputs": [],
      "source": [
        "#datadf_squad.to_csv('squad_3868.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp6Y9IdcSUKa"
      },
      "outputs": [],
      "source": [
        "#sample =squad_datadf.iloc[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bacB_4idSWrH"
      },
      "outputs": [],
      "source": [
        "#len(squad_datadf['question'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw3xRIiUYfRu"
      },
      "source": [
        "## loading the Quran QA & our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXcz0rLXrItz",
        "outputId": "646f83a3-efa4-4ed6-c56b-e1bf521d2f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVaduKPdHt95"
      },
      "outputs": [],
      "source": [
        "train_data_path = r'/content/drive/MyDrive/Quran_QA/Q_QA_task_original_code/quranqa/datasets/qrcd_v1.1_train.jsonl'\n",
        "AQQAC_data = r'/content/drive/MyDrive/Quran_QA/data/AQQAC_less_384.jsonl'\n",
        "dev_data_path = r'/content/drive/MyDrive/Quran_QA/Q_QA_task_original_code/quranqa/datasets/qrcd_v1.1_dev.jsonl'\n",
        "\n",
        "import json \n",
        "def read_data(datapath):\n",
        "  with open(datapath ,'rb') as fp:\n",
        "      datalist = list(fp)\n",
        "  data =[]\n",
        "  for json_str in datalist:\n",
        "      result = json.loads(json_str)\n",
        "      # print(f\"result: {result}\")\n",
        "      data.append(result)\n",
        "  return data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5hTAPFCIMf1"
      },
      "outputs": [],
      "source": [
        "quran_data=read_data(train_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoBoeiqPT45N",
        "outputId": "54cd6176-b1c3-4c2a-a8d8-c9c03854bcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "710\n"
          ]
        }
      ],
      "source": [
        "print(len(quran_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF02XKIuMvnZ"
      },
      "outputs": [],
      "source": [
        "val_data=read_data(dev_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXE2rqrJUGDW",
        "outputId": "3563a0c6-6e4a-45b0-eae5-3b58c9c4279e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109\n"
          ]
        }
      ],
      "source": [
        "print(len(val_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR-px0mr56wd"
      },
      "outputs": [],
      "source": [
        "AQQAC_data=read_data(AQQAC_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZzBosfqUI8P",
        "outputId": "04248db3-d416-4cf7-ceb5-112846caae33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "618\n"
          ]
        }
      ],
      "source": [
        "print(len(AQQAC_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gks7NLU6Mv5I"
      },
      "source": [
        "in this cell i will separate every sample that has many answers to a separate sample with a single answer , so this will make every sample have 1 answer for training , this is an initial idea until we see another idea\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSAuNKR6VTjd"
      },
      "outputs": [],
      "source": [
        "# single answer \n",
        "# multi  answer 3 -> 3 samples \n",
        "def split_multi_answers(data_list):\n",
        "  new_data=[]\n",
        "  for sample in data_list :\n",
        "    if len(sample['answers']) ==1:\n",
        "      new_data.append(sample)\n",
        "      continue\n",
        "    # print(sample)\n",
        "    for answer in sample['answers']:\n",
        "      new_sample={\n",
        "        'answers':[answer],\n",
        "        'passage':sample['passage'],\n",
        "        'pq_id':sample['pq_id'],\n",
        "        'question': sample['question'],\n",
        "        'surah':sample['surah'],\n",
        "        'verses':sample['verses']\n",
        "      }\n",
        "      new_data.append(new_sample)\n",
        "  return new_data \n",
        "quran_data= split_multi_answers(quran_data)\n",
        "AQQAC_data=split_multi_answers(AQQAC_data)\n",
        "# val_data= split_multi_answers(val_data)\n",
        "# 5 answers #\n",
        "# حمر مستنفرة فررت من قسورة "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkemN5PGUZP-",
        "outputId": "dda40233-9155-4357-d9b1-97d53eb30808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quran_data 861\n",
            "AQQAC_data 618\n",
            "val_data 109\n"
          ]
        }
      ],
      "source": [
        "print(\"quran_data\",len(quran_data))\n",
        "print(\"AQQAC_data\",len(AQQAC_data))\n",
        "print(\"val_data\",len(val_data))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcq6c94YekPs"
      },
      "source": [
        "shuffling the data then taking random 100 sample for validation (will test with our custom samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTfcdlvgYCw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c06c46-90d3-4939-e3c1-6ee351832b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quran_data before shuffle {'pq_id': '2:8-16_364', 'passage': 'ومن الناس من يقول آمنا بالله وباليوم الآخر وما هم بمؤمنين. يخادعون الله والذين آمنوا وما يخدعون إلا أنفسهم وما يشعرون. في قلوبهم مرض فزادهم الله مرضا ولهم عذاب أليم بما كانوا يكذبون. وإذا قيل لهم لا تفسدوا في الأرض قالوا إنما نحن مصلحون. ألا إنهم هم المفسدون ولكن لا يشعرون. وإذا قيل لهم آمنوا كما آمن الناس قالوا أنؤمن كما آمن السفهاء ألا إنهم هم السفهاء ولكن لا يعلمون. وإذا لقوا الذين آمنوا قالوا آمنا وإذا خلوا إلى شياطينهم قالوا إنا معكم إنما نحن مستهزئون. الله يستهزئ بهم ويمدهم في طغيانهم يعمهون. أولئك الذين اشتروا الضلالة بالهدى فما ربحت تجارتهم وما كانوا مهتدين.', 'surah': 2, 'verses': '8-16', 'question': 'لماذا سيُحاسب ويُعذب الضال يوم القيامة ان كان \"\"من يضلل الله فما له من هاد\"\" كما ورد من قوله تعالى في آية 23 و آية 36 من سورة الزمر؟', 'answers': [{'text': 'أولئك الذين اشتروا الضلالة بالهدى', 'start_char': 504}]}\n",
            "quran_data after shuffle {'pq_id': '3:33-41_122', 'passage': 'إن الله اصطفى آدم ونوحا وآل إبراهيم وآل عمران على العالمين. ذرية بعضها من بعض والله سميع عليم. إذ قالت امرأت عمران رب إني نذرت لك ما في بطني محررا فتقبل مني إنك أنت السميع العليم. فلما وضعتها قالت رب إني وضعتها أنثى والله أعلم بما وضعت وليس الذكر كالأنثى وإني سميتها مريم وإني أعيذها بك وذريتها من الشيطان الرجيم. فتقبلها ربها بقبول حسن وأنبتها نباتا حسنا وكفلها زكريا كلما دخل عليها زكريا المحراب وجد عندها رزقا قال يا مريم أنى لك هذا قالت هو من عند الله إن الله يرزق من يشاء بغير حساب. هنالك دعا زكريا ربه قال رب هب لي من لدنك ذرية طيبة إنك سميع الدعاء. فنادته الملائكة وهو قائم يصلي في المحراب أن الله يبشرك بيحيى مصدقا بكلمة من الله وسيدا وحصورا ونبيا من الصالحين. قال رب أنى يكون لي غلام وقد بلغني الكبر وامرأتي عاقر قال كذلك الله يفعل ما يشاء. قال رب اجعل لي آية قال آيتك ألا تكلم الناس ثلاثة أيام إلا رمزا واذكر ربك كثيرا وسبح بالعشي والإبكار.', 'surah': 3, 'verses': '33-41', 'question': 'كم ليلة امر الله زكريا الا يكلم الناس؟', 'answers': [{'text': 'ثلاثة أيام', 'start_char': 793}]}\n",
            "AQQAC_data before shuffle {'passage': 'ولو ترى إذ وقفوا على ربهم  قال أليس هذا بالحق  قالوا بلى وربنا  قال فذوقوا العذاب بما كنتم تكفرون  قد خسر الذين كذبوا بلقاء الله  حتى إذا جاءتهم الساعه بغته قالوا يا حسرتنا على ما فرطنا فيها وهم يحملون أوزارهم على ظهورهم  ألا ساء ما يزرون  وما الحياه الدنيا إلا لعب ولهو  وللدار الآخره خير للذين يتقون  أفلا تعقلون ', 'question': 'ما الشيء الذي يحمله الإنسان على ظهره يوم القيامه ويكون حملا ثقيلا عليه ', 'answers': [{'text': 'يحملون أوزارهم', 'start_char': 195}]}\n",
            "AQQAC_data after shuffle {'passage': 'سيقول السفهاء من الناس ما ولاهم عن قبلتهم التي كانوا عليها قل لله المشرق والمغرب يهدي من يشاء إلى صراط مستقيم', 'question': 'ماذا كان الرد من الله تعالى في تغيير القبله إلى المسجد الحرام ', 'answers': [{'text': 'لله المشرق والمغرب يهدي من يشاء إلى صراط مستقيم', 'start_char': 62}]}\n"
          ]
        }
      ],
      "source": [
        "# for sample in new_data : print(sample['answers'])\n",
        "from random import shuffle\n",
        "\n",
        "print(\"quran_data before shuffle\",quran_data[0])\n",
        "shuffle(quran_data)\n",
        "print(\"quran_data after shuffle\",quran_data[0])\n",
        "\n",
        "print(\"AQQAC_data before shuffle\",AQQAC_data[0])\n",
        "shuffle(AQQAC_data)\n",
        "print(\"AQQAC_data after shuffle\",AQQAC_data[0])\n",
        "\n",
        "# print(\"squad before shuffle\",squad_data_part[0])\n",
        "# shuffle(squad_data_part)\n",
        "# print(\"squad after shuffle\",squad_data_part[0])\n",
        "\n",
        "\n",
        "shuffle(val_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng9vPZSsVAui",
        "outputId": "7c742a6f-58b8-4a9d-d906-7fd44d1ccbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quran_data 861\n",
            "AQQAC_data 618\n",
            "val_data 109\n",
            "squad_data_part 1000\n"
          ]
        }
      ],
      "source": [
        "print(\"quran_data\",len(quran_data))\n",
        "print(\"AQQAC_data\",len(AQQAC_data))\n",
        "print(\"val_data\",len(val_data))\n",
        "print(\"squad_data_part\",len(squad_data_part))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yErpbR2RMN-y"
      },
      "source": [
        "## combined data [SQuAD & Quran QA & our data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcTbfn5eKOyE",
        "outputId": "8ec9127a-2cd3-4dee-ccb9-14248cdb5f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all data before shuffle {'pq_id': '22:23-24_311', 'passage': 'إن الله يدخل الذين آمنوا وعملوا الصالحات جنات تجري من تحتها الأنهار يحلون فيها من أساور من ذهب ولؤلؤا ولباسهم فيها حرير. وهدوا إلى الطيب من القول وهدوا إلى صراط الحميد.', 'surah': 22, 'verses': '23-24', 'question': 'ما هو أثر الكلام الطيب؟', 'answers': [{'text': 'هدوا إلى الطيب من القول وهدوا إلى صراط الحميد', 'start_char': 122}]}\n",
            "all data after shuffle {'pq_id': '62:1-4_164', 'passage': 'يسبح لله ما في السماوات وما في الأرض الملك القدوس العزيز الحكيم. هو الذي بعث في الأميين رسولا منهم يتلو عليهم آياته ويزكيهم ويعلمهم الكتاب والحكمة وإن كانوا من قبل لفي ضلال مبين. وآخرين منهم لما يلحقوا بهم وهو العزيز الحكيم. ذلك فضل الله يؤتيه من يشاء والله ذو الفضل العظيم.', 'surah': 62, 'verses': '1-4', 'question': 'ما المخلوقات التي تسبح الله؟', 'answers': [{'text': 'يسبح لله ما في السماوات وما في الأرض', 'start_char': 0}]}\n",
            "1479\n"
          ]
        }
      ],
      "source": [
        "all_data=[]\n",
        "all_data.extend(quran_data)\n",
        "# all_data.extend(squad_data_part)\n",
        "all_data.extend(AQQAC_data)\n",
        "\n",
        "from random import shuffle\n",
        "\n",
        "print(\"all data before shuffle\",all_data[500])\n",
        "shuffle(all_data)\n",
        "print(\"all data after shuffle\",all_data[500])\n",
        "\n",
        "print(len(all_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZm4YmvdXbNN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "all_datadf = pd.DataFrame(all_data)\n",
        "valdatadf = pd.DataFrame(val_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ogfz0FhXjhH",
        "outputId": "5d1bed22-1df6-457d-f838-8b801ab86860"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           pq_id                                            passage  surah  \\\n",
              "0    5:35-37_357  يا أيها الذين آمنوا اتقوا الله وابتغوا إليه ال...    5.0   \n",
              "1            NaN  إن الإنسان خلق هلوعا إذا مسه الشر جزوعا وإذا م...    NaN   \n",
              "2  7:159-162_231  ومن قوم موسى أمة يهدون بالحق وبه يعدلون. وقطعن...    7.0   \n",
              "3   11:77-83_362  ولما جاءت رسلنا لوطا سيء بهم وضاق بهم ذرعا وقا...   11.0   \n",
              "4   74:32-48_330  كلا والقمر. والليل إذ أدبر. والصبح إذا أسفر. إ...   74.0   \n",
              "\n",
              "    verses                                     question  \\\n",
              "0    35-37               ما هو فضل الجهاد في سبيل الله؟   \n",
              "1      NaN                             ما صفات المصلين    \n",
              "2  159-162   ما هي انواع الحيوانات التي ذكرت في القرآن؟   \n",
              "3    77-83  هل استخدم لفظ (المطر) في القرآن للعذاب فقط؟   \n",
              "4    32-48    ما هي الدلائل التي تشير بأن الانسان مخير؟   \n",
              "\n",
              "                                             answers  \n",
              "0  [{'text': 'جاهدوا في سبيله لعلكم تفلحون', 'sta...  \n",
              "1  [{'text': 'والذين في أموالهم حق معلوم للسائل و...  \n",
              "2            [{'text': 'السلوى', 'start_char': 216}]  \n",
              "3  [{'text': 'أمطرنا عليها حجارة من سجيل منضود', ...  \n",
              "4  [{'text': 'لمن شاء منكم أن يتقدم أو يتأخر', 's...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f684d9fd-eb36-4635-b476-809722a1e2b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pq_id</th>\n",
              "      <th>passage</th>\n",
              "      <th>surah</th>\n",
              "      <th>verses</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5:35-37_357</td>\n",
              "      <td>يا أيها الذين آمنوا اتقوا الله وابتغوا إليه ال...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>35-37</td>\n",
              "      <td>ما هو فضل الجهاد في سبيل الله؟</td>\n",
              "      <td>[{'text': 'جاهدوا في سبيله لعلكم تفلحون', 'sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>إن الإنسان خلق هلوعا إذا مسه الشر جزوعا وإذا م...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ما صفات المصلين</td>\n",
              "      <td>[{'text': 'والذين في أموالهم حق معلوم للسائل و...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7:159-162_231</td>\n",
              "      <td>ومن قوم موسى أمة يهدون بالحق وبه يعدلون. وقطعن...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>159-162</td>\n",
              "      <td>ما هي انواع الحيوانات التي ذكرت في القرآن؟</td>\n",
              "      <td>[{'text': 'السلوى', 'start_char': 216}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11:77-83_362</td>\n",
              "      <td>ولما جاءت رسلنا لوطا سيء بهم وضاق بهم ذرعا وقا...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>77-83</td>\n",
              "      <td>هل استخدم لفظ (المطر) في القرآن للعذاب فقط؟</td>\n",
              "      <td>[{'text': 'أمطرنا عليها حجارة من سجيل منضود', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>74:32-48_330</td>\n",
              "      <td>كلا والقمر. والليل إذ أدبر. والصبح إذا أسفر. إ...</td>\n",
              "      <td>74.0</td>\n",
              "      <td>32-48</td>\n",
              "      <td>ما هي الدلائل التي تشير بأن الانسان مخير؟</td>\n",
              "      <td>[{'text': 'لمن شاء منكم أن يتقدم أو يتأخر', 's...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f684d9fd-eb36-4635-b476-809722a1e2b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f684d9fd-eb36-4635-b476-809722a1e2b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f684d9fd-eb36-4635-b476-809722a1e2b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "all_datadf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_O8jR7Z8St_",
        "outputId": "8a1adec5-73d5-4817-be3c-ede3ceae541d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1479 entries, 0 to 1478\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   pq_id     861 non-null    object \n",
            " 1   passage   1479 non-null   object \n",
            " 2   surah     861 non-null    float64\n",
            " 3   verses    861 non-null    object \n",
            " 4   question  1479 non-null   object \n",
            " 5   answers   1479 non-null   object \n",
            "dtypes: float64(1), object(5)\n",
            "memory usage: 69.5+ KB\n"
          ]
        }
      ],
      "source": [
        "all_datadf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzMW-3-gYSkw"
      },
      "outputs": [],
      "source": [
        "sample =all_datadf.iloc[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlAUSdXnL3fX",
        "outputId": "c7efa932-182d-4796-faf6-f6022063b0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             passage  \\\n",
              "0  يا أيها الذين آمنوا اتقوا الله وابتغوا إليه ال...   \n",
              "1  إن الإنسان خلق هلوعا إذا مسه الشر جزوعا وإذا م...   \n",
              "2  ومن قوم موسى أمة يهدون بالحق وبه يعدلون. وقطعن...   \n",
              "3  ولما جاءت رسلنا لوطا سيء بهم وضاق بهم ذرعا وقا...   \n",
              "4  كلا والقمر. والليل إذ أدبر. والصبح إذا أسفر. إ...   \n",
              "\n",
              "                                      question  \\\n",
              "0               ما هو فضل الجهاد في سبيل الله؟   \n",
              "1                             ما صفات المصلين    \n",
              "2   ما هي انواع الحيوانات التي ذكرت في القرآن؟   \n",
              "3  هل استخدم لفظ (المطر) في القرآن للعذاب فقط؟   \n",
              "4    ما هي الدلائل التي تشير بأن الانسان مخير؟   \n",
              "\n",
              "                                             answers  \n",
              "0  [{'text': 'جاهدوا في سبيله لعلكم تفلحون', 'sta...  \n",
              "1  [{'text': 'والذين في أموالهم حق معلوم للسائل و...  \n",
              "2            [{'text': 'السلوى', 'start_char': 216}]  \n",
              "3  [{'text': 'أمطرنا عليها حجارة من سجيل منضود', ...  \n",
              "4  [{'text': 'لمن شاء منكم أن يتقدم أو يتأخر', 's...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c81739fe-aa13-4c1f-bab8-694aed6d05bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يا أيها الذين آمنوا اتقوا الله وابتغوا إليه ال...</td>\n",
              "      <td>ما هو فضل الجهاد في سبيل الله؟</td>\n",
              "      <td>[{'text': 'جاهدوا في سبيله لعلكم تفلحون', 'sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>إن الإنسان خلق هلوعا إذا مسه الشر جزوعا وإذا م...</td>\n",
              "      <td>ما صفات المصلين</td>\n",
              "      <td>[{'text': 'والذين في أموالهم حق معلوم للسائل و...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ومن قوم موسى أمة يهدون بالحق وبه يعدلون. وقطعن...</td>\n",
              "      <td>ما هي انواع الحيوانات التي ذكرت في القرآن؟</td>\n",
              "      <td>[{'text': 'السلوى', 'start_char': 216}]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ولما جاءت رسلنا لوطا سيء بهم وضاق بهم ذرعا وقا...</td>\n",
              "      <td>هل استخدم لفظ (المطر) في القرآن للعذاب فقط؟</td>\n",
              "      <td>[{'text': 'أمطرنا عليها حجارة من سجيل منضود', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>كلا والقمر. والليل إذ أدبر. والصبح إذا أسفر. إ...</td>\n",
              "      <td>ما هي الدلائل التي تشير بأن الانسان مخير؟</td>\n",
              "      <td>[{'text': 'لمن شاء منكم أن يتقدم أو يتأخر', 's...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c81739fe-aa13-4c1f-bab8-694aed6d05bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c81739fe-aa13-4c1f-bab8-694aed6d05bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c81739fe-aa13-4c1f-bab8-694aed6d05bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "all_datadf.drop(all_datadf.columns.difference(['question','answers','passage']), 1, inplace=True)\n",
        "all_datadf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNCv8os2L7G6",
        "outputId": "188017b7-1b29-4dc9-b454-588810ed185f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1479 entries, 0 to 1478\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   passage   1479 non-null   object\n",
            " 1   question  1479 non-null   object\n",
            " 2   answers   1479 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 34.8+ KB\n"
          ]
        }
      ],
      "source": [
        "all_datadf.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL-TbsEUMH3X",
        "outputId": "13e2fad4-bc96-4c19-c1e5-da1a42afa656"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1479"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(all_datadf['question'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHpIDNZQsfJm"
      },
      "source": [
        "## Data Viualization\n",
        "\n",
        "*   Histogram of the question length\n",
        "*   Histogram of passage length \n",
        "*   Histogram of the most common n words \n",
        "*   Histogram of most common n bi-grams\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3hBpagGPO2m"
      },
      "source": [
        "##### Visulaization for all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "tZmtvwa3PWkF",
        "outputId": "0cdee139-e120-4eff-98b6-ea17cec16e1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#all_datadf\n",
        "import seaborn as sns\n",
        "\n",
        "axs =sns.histplot([len(q.split()) for q in all_datadf['question'].tolist()])\n",
        "axs.set(title ='histogram of question length' ,xlabel = 'question length', ylabel='count')\n",
        "axs.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "WcpZeMf-Pj90",
        "outputId": "890d9252-a9cb-4d35-d499-a594c33143c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#all_datadf\n",
        "import seaborn as sns\n",
        "\n",
        "axs =sns.histplot([len(q.split()) for q in all_datadf['passage'].tolist()])\n",
        "axs.set(title ='histogram of passage length' ,xlabel = 'passage length', ylabel='count')\n",
        "axs.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "gvFRRMc8P1BD",
        "outputId": "ef84366f-2224-471a-deae-dd03c5c9b6a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"af7f88b5-b3e0-4e6f-9242-89a2230b97c6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"af7f88b5-b3e0-4e6f-9242-89a2230b97c6\")) {                    Plotly.newPlot(                        \"af7f88b5-b3e0-4e6f-9242-89a2230b97c6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"\\u0645\\u0646\",\"\\u0627\\u0644\\u0644\\u0647\",\"\\u0641\\u064a\",\"\\u0625\\u0646\",\"\\u0645\\u0627\",\"\\u0648\\u0644\\u0627\",\"\\u0627\\u0644\\u0630\\u064a\\u0646\",\"\\u0639\\u0644\\u0649\",\"\\u0644\\u0627\",\"\\u0623\\u0646\",\"\\u0625\\u0644\\u0627\",\"\\u0648\\u0645\\u0627\",\"\\u0642\\u0627\\u0644\",\"\\u064a\\u0627\",\"\\u0648\\u0645\\u0646\",\"\\u0625\\u0644\\u0649\",\"\\u0630\\u0644\\u0643\",\"\\u0648\\u0627\\u0644\\u0630\\u064a\\u0646\",\"\\u0647\\u0645\",\"\\u0644\\u0643\\u0645\",\"\\u0628\\u0647\",\"\\u0643\\u0627\\u0646\",\"\\u0623\\u0648\",\"\\u0644\\u0647\\u0645\",\"\\u0644\\u0647\",\"\\u0622\\u0645\\u0646\\u0648\\u0627\",\"\\u0627\\u0644\\u0623\\u0631\\u0636\",\"\\u062b\\u0645\",\"\\u0625\\u0630\\u0627\",\"\\u0628\\u0645\\u0627\"],\"xaxis\":\"x\",\"y\":[3289,2571,1409,1193,1083,905,871,854,832,799,775,756,664,566,495,450,437,401,399,393,392,389,386,371,364,339,330,329,328,314],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"word\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"word frequency\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('af7f88b5-b3e0-4e6f-9242-89a2230b97c6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#all_datadf\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "Counter(\" \".join(all_datadf[\"passage\"]).split()).most_common(200)\n",
        "labels, values = zip(*Counter(\" \".join(all_datadf[\"passage\"]).split()).most_common(30))\n",
        "\n",
        "fig = px.bar( x=labels, y=values)\n",
        "fig.update_layout(\n",
        "    title ='word frequency',\n",
        "    xaxis_title='word',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "LzFHnPbKQChA",
        "outputId": "ca2f7d8b-c4b4-4433-ee44-89459676d66c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b998ed2e-ed8c-404a-9946-2bae3cd79b5f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b998ed2e-ed8c-404a-9946-2bae3cd79b5f\")) {                    Plotly.newPlot(                        \"b998ed2e-ed8c-404a-9946-2bae3cd79b5f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"\\u0625\\u0646 \\u0627\\u0644\\u0644\\u0647\",\"\\u0627\\u0644\\u0630\\u064a\\u0646 \\u0622\\u0645\\u0646\\u0648\\u0627\",\"\\u0641\\u064a \\u0627\\u0644\\u0623\\u0631\\u0636\",\"\\u064a\\u0627 \\u0623\\u064a\\u0647\\u0627\",\"\\u0627\\u0644\\u0633\\u0645\\u0627\\u0648\\u0627\\u062a \\u0648\\u0627\\u0644\\u0623\\u0631\\u0636\",\"\\u0623\\u064a\\u0647\\u0627 \\u0627\\u0644\\u0630\\u064a\\u0646\",\"\\u0627\\u0644\\u0630\\u064a\\u0646 \\u0643\\u0641\\u0631\\u0648\\u0627\",\"\\u0645\\u0646 \\u0628\\u0639\\u062f\",\"\\u0625\\u0646 \\u0643\\u0646\\u062a\\u0645\",\"\\u0648\\u0627\\u0644\\u0630\\u064a\\u0646 \\u0647\\u0645\",\"\\u0645\\u0646 \\u0627\\u0644\\u0644\\u0647\",\"\\u0627\\u0644\\u0644\\u0647 \\u0625\\u0646\",\"\\u0633\\u0628\\u064a\\u0644 \\u0627\\u0644\\u0644\\u0647\",\"\\u0643\\u0644 \\u0634\\u064a\\u0621\",\"\\u0627\\u0644\\u0644\\u0647 \\u0648\\u0631\\u0633\\u0648\\u0644\\u0647\",\"\\u0625\\u0646 \\u0627\\u0644\\u0630\\u064a\\u0646\",\"\\u0645\\u0646 \\u0642\\u0628\\u0644\",\"\\u0641\\u064a \\u0630\\u0644\\u0643\",\"\\u0641\\u064a \\u0627\\u0644\\u0633\\u0645\\u0627\\u0648\\u0627\\u062a\",\"\\u064a\\u0627 \\u0642\\u0648\\u0645\"],\"xaxis\":\"x\",\"y\":[278,213,191,191,126,124,116,110,98,98,96,94,94,93,91,89,86,82,82,80],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"words\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"bi-gram frequency\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b998ed2e-ed8c-404a-9946-2bae3cd79b5f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#all_datadf\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "labels, values = zip(*Counter(ngrams(\" \".join(all_datadf[\"passage\"]).split(), 2)).most_common(20))\n",
        "labels =[' '.join(x) for x in labels]\n",
        "fig = px.bar( x=labels , y=values )\n",
        "fig.update_layout(\n",
        "    title ='bi-gram frequency',\n",
        "    xaxis_title='words',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "i2Hm0E6HQIsJ",
        "outputId": "03b4953d-b248-4ba8-973e-fc1944dab9ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"53742ad2-9b32-4ff0-aee8-f48b261effb5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"53742ad2-9b32-4ff0-aee8-f48b261effb5\")) {                    Plotly.newPlot(                        \"53742ad2-9b32-4ff0-aee8-f48b261effb5\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"\\u064a\\u0627 \\u0623\\u064a\\u0647\\u0627 \\u0627\\u0644\\u0630\\u064a\\u0646\",\"\\u0623\\u064a\\u0647\\u0627 \\u0627\\u0644\\u0630\\u064a\\u0646 \\u0622\\u0645\\u0646\\u0648\\u0627\",\"\\u0625\\u0646 \\u0641\\u064a \\u0630\\u0644\\u0643\",\"\\u0641\\u064a \\u0633\\u0628\\u064a\\u0644 \\u0627\\u0644\\u0644\\u0647\",\"\\u0627\\u0644\\u0644\\u0647 \\u0625\\u0646 \\u0627\\u0644\\u0644\\u0647\",\"\\u0645\\u0646 \\u062f\\u0648\\u0646 \\u0627\\u0644\\u0644\\u0647\",\"\\u0641\\u0628\\u0623\\u064a \\u0622\\u0644\\u0627\\u0621 \\u0631\\u0628\\u0643\\u0645\\u0627\",\"\\u0639\\u0644\\u0649 \\u0643\\u0644 \\u0634\\u064a\\u0621\",\"\\u0622\\u0644\\u0627\\u0621 \\u0631\\u0628\\u0643\\u0645\\u0627 \\u062a\\u0643\\u0630\\u0628\\u0627\\u0646.\",\"\\u062a\\u062c\\u0631\\u064a \\u0645\\u0646 \\u062a\\u062d\\u062a\\u0647\\u0627\",\"\\u0645\\u0646 \\u062a\\u062d\\u062a\\u0647\\u0627 \\u0627\\u0644\\u0623\\u0646\\u0647\\u0627\\u0631\",\"\\u0625\\u0646 \\u0627\\u0644\\u0644\\u0647 \\u0644\\u0627\",\"\\u0642\\u0627\\u0644 \\u064a\\u0627 \\u0642\\u0648\\u0645\",\"\\u0628\\u0627\\u0644\\u0644\\u0647 \\u0648\\u0627\\u0644\\u064a\\u0648\\u0645 \\u0627\\u0644\\u0622\\u062e\\u0631\",\"\\u062c\\u0646\\u0627\\u062a \\u062a\\u062c\\u0631\\u064a \\u0645\\u0646\",\"\\u0639\\u064a\\u0633\\u0649 \\u0627\\u0628\\u0646 \\u0645\\u0631\\u064a\\u0645\",\"\\u0644\\u0643\\u0645 \\u0625\\u0646 \\u0643\\u0646\\u062a\\u0645\",\"\\u0641\\u064a \\u0627\\u0644\\u0633\\u0645\\u0627\\u0648\\u0627\\u062a \\u0648\\u0627\\u0644\\u0623\\u0631\\u0636\",\"\\u0641\\u064a \\u0630\\u0644\\u0643 \\u0644\\u0622\\u064a\\u0627\\u062a\",\"\\u062e\\u0644\\u0642 \\u0627\\u0644\\u0633\\u0645\\u0627\\u0648\\u0627\\u062a \\u0648\\u0627\\u0644\\u0623\\u0631\\u0636\"],\"xaxis\":\"x\",\"y\":[124,123,73,70,67,60,55,52,52,46,46,44,43,42,39,38,37,36,35,34],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"words\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"tri-gram frequency\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('53742ad2-9b32-4ff0-aee8-f48b261effb5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#all_datadf\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "labels, values = zip(*Counter(ngrams(\" \".join(all_datadf[\"passage\"]).split(), 3)).most_common(20))\n",
        "labels =[' '.join(x) for x in labels]\n",
        "fig = px.bar( x=labels , y=values )\n",
        "fig.update_layout(\n",
        "    title ='tri-gram frequency',\n",
        "    xaxis_title='words',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVcFJYdmxbaN"
      },
      "outputs": [],
      "source": [
        "# [len(q.split()) for q in datadf['question'].tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "LhwYdXrC8wZa",
        "outputId": "8a2b6254-2d65-4785-9a57-eebf708b3572"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-253bbcbeed17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAQQAC_datadf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'histogram of question length'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mxlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'question length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AQQAC_datadf' is not defined"
          ]
        }
      ],
      "source": [
        "#AQQAC_datadf\n",
        "import seaborn as sns\n",
        "\n",
        "axs =sns.histplot([len(q.split()) for q in AQQAC_datadf['question'].tolist()])\n",
        "axs.set(title ='histogram of question length' ,xlabel = 'question length', ylabel='count')\n",
        "axs.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypMSUtW0szSI"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "axs =sns.histplot([len(q.split()) for q in datadf['question'].tolist()])\n",
        "axs.set(title ='histogram of question length' ,xlabel = 'question length', ylabel='count')\n",
        "axs.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js6hrLNf88Lu"
      },
      "outputs": [],
      "source": [
        "#AQQAC_datadf\n",
        "import seaborn as sns\n",
        "\n",
        "axs =sns.histplot([len(q.split()) for q in AQQAC_datadf['passage'].tolist()])\n",
        "axs.set(title ='histogram of passage length' ,xlabel = 'passage length', ylabel='count')\n",
        "axs.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gIpGxzRuuvo"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "axs =sns.histplot([len(q.split()) for q in datadf['passage'].tolist()])\n",
        "axs.set(title ='histogram of passage length' ,xlabel = 'passage length', ylabel='count')\n",
        "axs.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDOQ85zVQWej"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(\" \".join(datadf[\"passage\"]).split()).most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GLyv_Qr9OVL"
      },
      "outputs": [],
      "source": [
        "#AQQAC_datadf\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "Counter(\" \".join(AQQAC_datadf[\"passage\"]).split()).most_common(200)\n",
        "labels, values = zip(*Counter(\" \".join(AQQAC_datadf[\"passage\"]).split()).most_common(30))\n",
        "\n",
        "fig = px.bar( x=labels, y=values)\n",
        "fig.update_layout(\n",
        "    title ='word frequency',\n",
        "    xaxis_title='word',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpZ932xV9ssD"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "Counter(\" \".join(datadf[\"passage\"]).split()).most_common(200)\n",
        "labels, values = zip(*Counter(\" \".join(datadf[\"passage\"]).split()).most_common(30))\n",
        "\n",
        "fig = px.bar( x=labels, y=values)\n",
        "fig.update_layout(\n",
        "    title ='word frequency',\n",
        "    xaxis_title='word',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LGSzrLE9plu"
      },
      "outputs": [],
      "source": [
        "#AQQAC_datadf\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "labels, values = zip(*Counter(ngrams(\" \".join(AQQAC_datadf[\"passage\"]).split(), 2)).most_common(20))\n",
        "labels =[' '.join(x) for x in labels]\n",
        "fig = px.bar( x=labels , y=values )\n",
        "fig.update_layout(\n",
        "    title ='bi-gram frequency',\n",
        "    xaxis_title='words',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRAyf8bVaPiu"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "labels, values = zip(*Counter(ngrams(\" \".join(datadf[\"passage\"]).split(), 2)).most_common(20))\n",
        "labels =[' '.join(x) for x in labels]\n",
        "fig = px.bar( x=labels , y=values )\n",
        "fig.update_layout(\n",
        "    title ='bi-gram frequency',\n",
        "    xaxis_title='words',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGzltoiQ99lg"
      },
      "outputs": [],
      "source": [
        "#AQQAC_datadf\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "labels, values = zip(*Counter(ngrams(\" \".join(AQQAC_datadf[\"passage\"]).split(), 3)).most_common(20))\n",
        "labels =[' '.join(x) for x in labels]\n",
        "fig = px.bar( x=labels , y=values )\n",
        "fig.update_layout(\n",
        "    title ='tri-gram frequency',\n",
        "    xaxis_title='words',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVtItxIW6aRj"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "labels, values = zip(*Counter(ngrams(\" \".join(datadf[\"passage\"]).split(), 3)).most_common(20))\n",
        "labels =[' '.join(x) for x in labels]\n",
        "fig = px.bar( x=labels , y=values )\n",
        "fig.update_layout(\n",
        "    title ='tri-gram frequency',\n",
        "    xaxis_title='words',\n",
        "    yaxis_title='count'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv_ITnfQYmKa"
      },
      "source": [
        "## data preparing (preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9_umo1QYsZf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "7efe9082-0a13-4848-96c8-9ef0ada8d9b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1935\u001b[0m         \u001b[0;31m# File, but it doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1936\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"file {url_or_filename} not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1937\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: file /content/drive/MyDrive/Quran_QA/quranBERT/8epochs/config.json not found",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-f1f08fc8a59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Quran_QA/quranBERT_moreepochs/checkpoint-6236/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Quran_QA/quranBERT/8epochs/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# inputs id , attention mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# hospital -> 340 --> 111111100000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 config = AutoConfig.from_pretrained(\n\u001b[0;32m--> 485\u001b[0;31m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m                 )\n\u001b[1;32m    487\u001b[0m             \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             raise EnvironmentError(\n\u001b[0;32m--> 631\u001b[0;31m                 \u001b[0;34mf\"Can't load config for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;34mf\"Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a directory \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load config for '/content/drive/MyDrive/Quran_QA/quranBERT/8epochs/'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/drive/MyDrive/Quran_QA/quranBERT/8epochs/' is the correct path to a directory containing a config.json file"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "transformer_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "model_path = \"/content/drive/MyDrive/Quran_QA/quranBERT_moreepochs/checkpoint-6236/\"\n",
        "model_path = \"/content/drive/MyDrive/Quran_QA/quranBERT/8epochs/\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path) # inputs id , attention mask \n",
        "# hospital -> 340 --> 111111100000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uYwpnt6zRMp"
      },
      "outputs": [],
      "source": [
        "sample =all_datadf.sample(3).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "E1n1nFINzbo4",
        "outputId": "613b5fd6-87a3-4461-8931-15c5bb1f8a85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                            passage  \\\n",
              "0    319  قد أفلح المؤمنون الذين هم في صلاتهم خاشعون وال...   \n",
              "1    966  قل للمخلفين من الأعراب ستدعون إلى قوم أولي بأس...   \n",
              "2    467  يا أيها النبي جاهد الكفار والمنافقين واغلظ علي...   \n",
              "\n",
              "                                            question  \\\n",
              "0                               ما هي صفات المؤمنين    \n",
              "1  لماذا لا يكتفي المسلمون بالقرآن الكريم ويلجأون...   \n",
              "2                     ما حكم من يرتد عن دين الإسلام؟   \n",
              "\n",
              "                                             answers  \n",
              "0  [{'text': 'والذين هم للزكاه فاعلون', 'start_ch...  \n",
              "1  [{'text': 'من يطع الله ورسوله يدخله جنات تجري ...  \n",
              "2  [{'text': 'ما لهم في الأرض من ولي ولا نصير', '...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2553b80-c344-4fc9-a17c-15195c7d8784\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>passage</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>319</td>\n",
              "      <td>قد أفلح المؤمنون الذين هم في صلاتهم خاشعون وال...</td>\n",
              "      <td>ما هي صفات المؤمنين</td>\n",
              "      <td>[{'text': 'والذين هم للزكاه فاعلون', 'start_ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>966</td>\n",
              "      <td>قل للمخلفين من الأعراب ستدعون إلى قوم أولي بأس...</td>\n",
              "      <td>لماذا لا يكتفي المسلمون بالقرآن الكريم ويلجأون...</td>\n",
              "      <td>[{'text': 'من يطع الله ورسوله يدخله جنات تجري ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>467</td>\n",
              "      <td>يا أيها النبي جاهد الكفار والمنافقين واغلظ علي...</td>\n",
              "      <td>ما حكم من يرتد عن دين الإسلام؟</td>\n",
              "      <td>[{'text': 'ما لهم في الأرض من ولي ولا نصير', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2553b80-c344-4fc9-a17c-15195c7d8784')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2553b80-c344-4fc9-a17c-15195c7d8784 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2553b80-c344-4fc9-a17c-15195c7d8784');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3FO4U1BXJam",
        "outputId": "46301fed-5abd-4d13-a7e1-34e5ab4267b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[2, 394, 634, 20598, 15970, 3, 602, 1600, 182, 194, 17315, 319, 860, 1891, 305, 27874, 336, 54821, 2557, 6767, 1891, 352, 12068, 185, 53183, 6767, 1891, 7780, 845, 195, 16559, 319, 6767, 1891, 10398, 2665, 201, 6816, 319, 981, 323, 50328, 336, 440, 394, 3852, 228, 559, 1315, 336, 19559, 650, 1382, 8680, 4170, 3177, 7329, 2905, 563, 56825, 7059, 1891, 5356, 5326, 6767, 1891, 16377, 4660, 336, 560, 52622, 201, 29907, 319, 6767, 1891, 323, 51499, 336, 17352, 319, 10331, 1891, 1499, 53547, 319, 860, 2074, 36541, 36842, 1891, 764, 1645, 319, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 3346, 391, 29757, 11995, 33563, 3252, 4507, 6237, 319, 15394, 1, 105, 3, 2903, 13396, 24501, 306, 2345, 1795, 17130, 2557, 360, 14624, 22494, 3850, 5128, 32663, 20559, 440, 15868, 319, 1022, 946, 414, 330, 1380, 13123, 647, 46544, 24754, 1613, 589, 22982, 547, 10097, 379, 306, 600, 640, 2552, 593, 34064, 181, 12892, 321, 20, 1117, 323, 39980, 18184, 662, 323, 2345, 964, 18184, 662, 323, 6504, 18184, 623, 4703, 232, 647, 35534, 5319, 195, 50195, 5826, 306, 35722, 35622, 623, 503, 314, 640, 58383, 34064, 181, 12892, 321, 20, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 394, 2441, 306, 55973, 352, 1911, 1126, 105, 3, 1955, 11910, 8626, 17948, 52006, 12489, 50204, 35650, 182, 231, 2634, 34135, 14934, 41134, 491, 38895, 16915, 20, 10222, 10685, 10515, 394, 9466, 8404, 9466, 2446, 36499, 30797, 330, 446, 4771, 336, 2512, 330, 1199, 407, 22613, 330, 1177, 993, 32024, 981, 331, 1694, 27147, 647, 35534, 306, 6819, 195, 1022, 503, 34023, 181, 2562, 16459, 1493, 1613, 503, 22982, 640, 58383, 201, 647, 34064, 181, 12892, 321, 305, 6449, 47970, 1177, 1493, 305, 2147, 306, 1033, 662, 25955, 20, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'start_positions': [25, 70, 81], 'end_positions': [31, 90, 88]}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "def preprocess_function(examples): \n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"passage\"].tolist(),\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    # visualization : max length , most common word , most common bi-gram , histogram of lengths \n",
        "    # {'input_ids': [ids], 'attention_mask':[111000], 'offest_mapping':[(1,5),(6,8)...] }\n",
        "    # print(inputs)\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    # print(offset_mapping)\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    # print(answers)\n",
        "    # print(offset_mapping) \n",
        "    # print(answers)\n",
        "    for i, offset in enumerate(offset_mapping): #loop every sample \n",
        "        answer = answers[i]\n",
        "        # print(f'ans #{i}={answer}')\n",
        "        start_char = answer[0][\"start_char\"]\n",
        "        end_char = answer[0][\"start_char\"] + len(answer[0][\"text\"])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        # print(sequence_ids)\n",
        "        # Find the start and end of the passage 0 , 1 \n",
        "        #متي نزل الوحي إنا انزلناه في ليلة القدر --->\n",
        "        #input_ids  : 23 43 56 56 78 90 95 67 \n",
        "        #sequence_id: 0  0  0  1  1  1 \n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        passage_start = idx\n",
        "\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        passage_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the passage, label it (0, 0)\n",
        "        if offset[passage_start][0] > end_char or offset[passage_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = passage_start\n",
        "            while idx <= passage_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "          \n",
        "            start_positions.append(idx - 1)\n",
        "            idx = passage_end\n",
        "            while idx >= passage_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions \n",
        "    inputs[\"end_positions\"] = end_positions     \n",
        "    return inputs\n",
        "preprocess_function(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sw1O95dayD2"
      },
      "outputs": [],
      "source": [
        "# tokenized_data = preprocess_function(datadf)\n",
        "tokenized_val_data = preprocess_function(valdatadf)\n",
        "# tokenized_AQQAC_data=preprocess_function(AQQAC_datadf)\n",
        "tokenized_all_data=preprocess_function(all_datadf)\n",
        "\n",
        "from datasets import Dataset\n",
        "# dataset= Dataset.from_dict(tokenized_data)\n",
        "# AQQAC_data=Dataset.from_dict(tokenized_AQQAC_data)\n",
        "valdataset= Dataset.from_dict(tokenized_val_data)\n",
        "all_data=Dataset.from_dict(tokenized_all_data)\n",
        "#pandas , dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnzadAUB8cmR",
        "outputId": "50878170-2f47-49b0-df4a-aadb2fd0e23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "    num_rows: 1479\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wqtApMruihi"
      },
      "source": [
        "## loading model , training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBW5tlyhs9hL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "03cb176f-abe2-41c8-a5a3-53e3b4055e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/Quran_QA/quranBERT_moreepochs/checkpoint-12472/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Quran_QA/quranBERT_moreepochs/checkpoint-12472\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-db9a33a1695f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model_path=\"/content/drive/MyDrive/Quran_QA/quranBERT/checkpoint-6236\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         raise ValueError(\n\u001b[1;32m    449\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLAX_WEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m                     raise EnvironmentError(\n\u001b[0;32m-> 1322\u001b[0;31m                         \u001b[0;34mf\"Error no file named {WEIGHTS_NAME} found in directory {pretrained_model_name_or_path} but \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m                         \u001b[0;34m\"there is a file for Flax weights. Use `from_flax=True` to load this model from those \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0;34m\"weights.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Error no file named pytorch_model.bin found in directory /content/drive/MyDrive/Quran_QA/quranBERT_moreepochs/checkpoint-12472 but there is a file for Flax weights. Use `from_flax=True` to load this model from those weights."
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "# model_path=\"/content/drive/MyDrive/Quran_QA/quranBERT/checkpoint-6236\"\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_path , from_flax=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D45Gz7dUDcGr"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "# model = AutoModelForQuestionAnswering.from_pretrained(transformer_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHxKFrc7ejKT"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm_probability=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Np2qfmdm66",
        "outputId": "5c984f61-84fa-4c81-e210-a4e1090685be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Quran_QA/models/quranBERTqa_cutout\",\n",
        "    save_strategy='steps',\n",
        "    save_steps =1480,\n",
        "    evaluation_strategy= \"epoch\",\n",
        "    learning_rate= 1e-5,\n",
        "    per_device_train_batch_size=2 ,\n",
        "    per_device_eval_batch_size=2 ,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh_4vSHNd8jw"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset= all_data,\n",
        "    eval_dataset=valdataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pMn2oDnTcZK",
        "outputId": "ea7d58b5-e8de-4357-ca86-039ed05c63b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "    num_rows: 1479\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "lugP_HHzfDyd",
        "outputId": "0d14e087-63b9-4c81-ce83-59192f752689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1479\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2960\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1398\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT8poybmS6qN"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(model_path+'all3data2epochwith9k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAIaqG99bqiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46af3c2-9ec4-4e5b-f3b4-cb2ea020832f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960/added_tokens.json. We won't load it.\n",
            "loading file /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960/vocab.txt\n",
            "loading file /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960/tokenizer.json\n",
            "loading file None\n",
            "loading file /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960/special_tokens_map.json\n",
            "loading file /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960/tokenizer_config.json\n",
            "loading configuration file /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960\",\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 64000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
            "\n",
            "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer , AutoTokenizer\n",
        "model_path= \"/content/drive/MyDrive/Quran_QA/models/quranBERTqa_2/checkpoint-740\"\n",
        "model_path= \"/content/drive/MyDrive/Quran_QA/models/quranBERTqa_3/checkpoint-4960\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "model.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NApmh-SusBI"
      },
      "source": [
        "## testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPhfA1kSoty4"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from scipy.special import softmax\n",
        "import torch\n",
        "\n",
        "min_answer_length=3\n",
        "number_of_required_answers = 5\n",
        "def quran_qa(text , question, show_all=False):\n",
        "    ranked_answers=[]\n",
        "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\").to(\"cuda\") \n",
        "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "    # print(inputs)\n",
        "    outputs = model(**inputs) # predict two lists ( startsss , endsss ) argmax [3 , 4, 5 , 6 ,-4 , 3]\n",
        "    # print(outputs)\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "\n",
        "    # Get the most likely beginning of answer with the argmax of the score\n",
        "    # answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_starts_probs = softmax(torch.topk(answer_start_scores , 5).values.cpu().detach().numpy())[0]\n",
        "    # print(answer_starts_probs)\n",
        "    answer_starts =  torch.topk(answer_start_scores , 5).indices\n",
        "    # Get the most likely end of answer with the argmax of the score\n",
        "    # answer_end = torch.argmax(answer_end_scores) + 1\n",
        "    answer_ends_probs = softmax(torch.topk(answer_end_scores, 5).values.cpu().detach().numpy())[0]\n",
        "    answer_ends = torch.topk(answer_end_scores, 5).indices +1\n",
        "    print(f\"Question: {question}\")\n",
        "    idx =0\n",
        "    for i , answer_start in enumerate(answer_starts.tolist()[0]):\n",
        "     for j , answer_end in enumerate(answer_ends.tolist()[0]):\n",
        "        idx+=1\n",
        "        if (\n",
        "                answer_end < answer_start\n",
        "                or answer_end - answer_start + 1 < min_answer_length\n",
        "            ):\n",
        "                continue\n",
        "        answer = tokenizer.convert_tokens_to_string(\n",
        "            tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])\n",
        "        )\n",
        "        \n",
        "        ranked_answers.append(\n",
        "            {\n",
        "                'answer': answer,\n",
        "                  'rank' : len(ranked_answers)+1,\n",
        "                  'score':float(answer_starts_probs[i]*answer_ends_probs[j])\n",
        "            }\n",
        "        )\n",
        "    #sort by probability \n",
        "    ranked_answers.sort(key =lambda x : x['score'], reverse =True)\n",
        "    ranked_answers = ranked_answers[:number_of_required_answers]\n",
        "    # reset rank \n",
        "    for i , answer in enumerate(ranked_answers): answer['rank']=i+1\n",
        "    if len(ranked_answers)==0: raise BaseException(\"empty list \")\n",
        "    print('top predicted answer:', )\n",
        "    return ranked_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB_R83b8fn92"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fZskhu2VaKC"
      },
      "source": [
        "### testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnWWy-EYp9cC",
        "outputId": "498f5635-57a5-4724-8b05-131209788335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answers': [{'start_char': 504, 'text': 'أولئك الذين اشتروا الضلالة بالهدى'}],\n",
              " 'passage': 'ومن الناس من يقول آمنا بالله وباليوم الآخر وما هم بمؤمنين. يخادعون الله والذين آمنوا وما يخدعون إلا أنفسهم وما يشعرون. في قلوبهم مرض فزادهم الله مرضا ولهم عذاب أليم بما كانوا يكذبون. وإذا قيل لهم لا تفسدوا في الأرض قالوا إنما نحن مصلحون. ألا إنهم هم المفسدون ولكن لا يشعرون. وإذا قيل لهم آمنوا كما آمن الناس قالوا أنؤمن كما آمن السفهاء ألا إنهم هم السفهاء ولكن لا يعلمون. وإذا لقوا الذين آمنوا قالوا آمنا وإذا خلوا إلى شياطينهم قالوا إنا معكم إنما نحن مستهزئون. الله يستهزئ بهم ويمدهم في طغيانهم يعمهون. أولئك الذين اشتروا الضلالة بالهدى فما ربحت تجارتهم وما كانوا مهتدين.',\n",
              " 'pq_id': '2:8-16_364',\n",
              " 'question': 'لماذا سيُحاسب ويُعذب الضال يوم القيامة ان كان \"\"من يضلل الله فما له من هاد\"\" كما ورد من قوله تعالى في آية 23 و آية 36 من سورة الزمر؟',\n",
              " 'surah': 2,\n",
              " 'verses': '8-16'}"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6F2aIVLp-hy"
      },
      "outputs": [],
      "source": [
        "def compare_sample(index):\n",
        "  print(index)\n",
        "  print(f\"passage :{data[index]['passage']}\")\n",
        "  print(f'actual question :{data[index][\"question\"]}')\n",
        "  print(f\"actual answer : {data[index]['answers']}\")\n",
        "  return quran_qa(data[index]['passage'], data[index]['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOu4RvD32her"
      },
      "outputs": [],
      "source": [
        "def compare_val_sample(index):\n",
        "  print(index)\n",
        "  print(f\"passage :{val_data[index]['passage']}\")\n",
        "  print(f'actual question :{val_data[index][\"question\"]}')\n",
        "  print(f\"actual answer : {val_data[index]['answers']}\")\n",
        "  return quran_qa(val_data[index]['passage'], val_data[index]['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyBPXiqxrETZ",
        "outputId": "d3e6ec00-fd97-4582-fc9b-b44e1865aa90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "passage :ولئن سألتهم من خلق السماوات والأرض وسخر الشمس والقمر ليقولن الله فأنى يؤفكون. الله يبسط الرزق لمن يشاء من عباده ويقدر له إن الله بكل شيء عليم. ولئن سألتهم من نزل من السماء ماء فأحيا به الأرض من بعد موتها ليقولن الله قل الحمد لله بل أكثرهم لا يعقلون. وما هذه الحياة الدنيا إلا لهو ولعب وإن الدار الآخرة لهي الحيوان لو كانوا يعلمون. فإذا ركبوا في الفلك دعوا الله مخلصين له الدين فلما نجاهم إلى البر إذا هم يشركون. ليكفروا بما آتيناهم وليتمتعوا فسوف يعلمون. أولم يروا أنا جعلنا حرما آمنا ويتخطف الناس من حولهم أفبالباطل يؤمنون وبنعمة الله يكفرون. ومن أظلم ممن افترى على الله كذبا أو كذب بالحق لما جاءه أليس في جهنم مثوى للكافرين. والذين جاهدوا فينا لنهدينهم سبلنا وإن الله لمع المحسنين.\n",
            "actual question :ماذا يشمل الإحسان؟\n",
            "actual answer : [{'text': 'الذين جاهدوا فينا لنهدينهم سبلنا', 'start_char': 628}]\n",
            "Question: ماذا يشمل الإحسان؟\n",
            "top predicted answer:\n",
            "[{'answer': 'والذين جاهدوا فينا لنهدينهم سبلنا وإن',\n",
            "  'rank': 1,\n",
            "  'score': 0.35142165422439575},\n",
            " {'answer': 'جاهدوا فينا لنهدينهم سبلنا وإن',\n",
            "  'rank': 2,\n",
            "  'score': 0.15579360723495483},\n",
            " {'answer': 'والذين جاهدوا فينا لنهدينهم سبلنا وإن الله لمع المحسنين. [SEP]',\n",
            "  'rank': 3,\n",
            "  'score': 0.08820924907922745},\n",
            " {'answer': 'والذين جاهدوا فينا لنهدينهم سبلنا',\n",
            "  'rank': 4,\n",
            "  'score': 0.05483787879347801},\n",
            " {'answer': 'جاهدوا فينا لنهدينهم سبلنا وإن الله لمع المحسنين. [SEP]',\n",
            "  'rank': 5,\n",
            "  'score': 0.03910527005791664}]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(compare_val_sample(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsw4rOg_sT0r",
        "outputId": "337573a9-12c0-496d-91b1-8b4875750475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "87\n",
            "passage :وداوود وسليمان إذ يحكمان في الحرث إذ نفشت فيه غنم القوم وكنا لحكمهم شاهدين. ففهمناها سليمان وكلا آتينا حكما وعلما وسخرنا مع داوود الجبال يسبحن والطير وكنا فاعلين. وعلمناه صنعة لبوس لكم لتحصنكم من بأسكم فهل أنتم شاكرون. ولسليمان الريح عاصفة تجري بأمره إلى الأرض التي باركنا فيها وكنا بكل شيء عالمين. ومن الشياطين من يغوصون له ويعملون عملا دون ذلك وكنا لهم حافظين.\n",
            "actual question :ما هي انواع الحيوانات التي ذكرت في القرآن؟\n",
            "actual answer : [{'text': 'الطير', 'start_char': 144}]\n",
            "Question: ما هي انواع الحيوانات التي ذكرت في القرآن؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'والطير وكنا', 'rank': 1, 'score': 0.20644284784793854},\n",
              " {'answer': 'والطير', 'rank': 2, 'score': 0.1501893550157547},\n",
              " {'answer': 'الجبال يسبحن والطير وكنا',\n",
              "  'rank': 3,\n",
              "  'score': 0.12220805883407593},\n",
              " {'answer': 'الجبال يسبحن والطير', 'rank': 4, 'score': 0.0889076516032219},\n",
              " {'answer': '##ير وكنا', 'rank': 5, 'score': 0.0626741424202919}]"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_sample(87)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTC0EVFHsdSH",
        "outputId": "8158fe5f-8ff0-4ba8-e970-322d9ffe9c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "459\n",
            "passage :قد خلت من قبلكم سنن فسيروا في الأرض فانظروا كيف كان عاقبة المكذبين. هذا بيان للناس وهدى وموعظة للمتقين. ولا تهنوا ولا تحزنوا وأنتم الأعلون إن كنتم مؤمنين. إن يمسسكم قرح فقد مس القوم قرح مثله وتلك الأيام نداولها بين الناس وليعلم الله الذين آمنوا ويتخذ منكم شهداء والله لا يحب الظالمين. وليمحص الله الذين آمنوا ويمحق الكافرين. أم حسبتم أن تدخلوا الجنة ولما يعلم الله الذين جاهدوا منكم ويعلم الصابرين. ولقد كنتم تمنون الموت من قبل أن تلقوه فقد رأيتموه وأنتم تنظرون. وما محمد إلا رسول قد خلت من قبله الرسل أفإن مات أو قتل انقلبتم على أعقابكم ومن ينقلب على عقبيه فلن يضر الله شيئا وسيجزي الله الشاكرين.\n",
            "actual question :ما هو فضل الجهاد في سبيل الله؟\n",
            "actual answer : [{'text': 'أن تدخلوا الجنة', 'start_char': 334}]\n",
            "Question: ما هو فضل الجهاد في سبيل الله؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'وليمحص الله الذين آمنوا ويمحق الكافرين. أم حسبتم أن تدخلوا الجنة ولما',\n",
              "  'rank': 1,\n",
              "  'score': 0.10851085931062698},\n",
              " {'answer': 'وليمحص الله الذين آمنوا ويمحق الكافرين. أم حسبتم أن تدخلوا الجنة ولما يعلم الله الذين جاهدوا منكم ويعلم الصابرين',\n",
              "  'rank': 2,\n",
              "  'score': 0.09276370704174042},\n",
              " {'answer': 'أم حسبتم أن تدخلوا الجنة ولما',\n",
              "  'rank': 3,\n",
              "  'score': 0.07996600866317749},\n",
              " {'answer': 'أم حسبتم أن تدخلوا الجنة ولما يعلم الله الذين جاهدوا منكم ويعلم الصابرين',\n",
              "  'rank': 4,\n",
              "  'score': 0.0683613047003746},\n",
              " {'answer': 'وليمحص الله الذين آمنوا ويمحق الكافرين. أم',\n",
              "  'rank': 5,\n",
              "  'score': 0.05460195243358612}]"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compare_sample(459)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yga3LNvcsj0M",
        "outputId": "c68ab85b-88e8-4fdc-ab39-c39acb82bcf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n",
            "passage :قل يا أيها الكافرون. لا أعبد ما تعبدون. ولا أنتم عابدون ما أعبد. ولا أنا عابد ما عبدتم. ولا أنتم عابدون ما أعبد. لكم دينكم ولي دين.\n",
            "actual question :هل سمح الإسلام بحرية الاعتقاد بالدخول إلى الإسلام؟\n",
            "actual answer : [{'text': 'قل يا أيها الكافرون لا أعبد ما تعبدون ولا أنتم عابدون ما أعبد ولا أنا عابد ما عبدتم ولا أنتم عابدون ما أعبد لكم دينكم ولي دين', 'start_char': 0}]\n",
            "Question: هل سمح الإسلام بحرية الاعتقاد بالدخول إلى الإسلام؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'قل يا أيها الكافرون. لا أعبد ما تعبدون. ولا أنتم عابدون ما أعبد. ولا أنا عابد ما عبدتم. ولا أنتم عابدون ما أعبد. لكم دينكم ولي دين.',\n",
              "  'rank': 1,\n",
              "  'score': 0.14466306567192078},\n",
              " {'answer': 'لكم دينكم ولي دين.', 'rank': 2, 'score': 0.12654350697994232},\n",
              " {'answer': 'قل يا أيها الكافرون. لا أعبد ما تعبدون. ولا أنتم عابدون ما أعبد. ولا أنا عابد ما عبدتم. ولا أنتم عابدون ما أعبد. لكم دينكم ولي دين',\n",
              "  'rank': 3,\n",
              "  'score': 0.12129538506269455},\n",
              " {'answer': 'لكم دينكم ولي دين', 'rank': 4, 'score': 0.10610271245241165},\n",
              " {'answer': 'قل يا أيها الكافرون. لا أعبد ما تعبدون. ولا أنتم عابدون ما أعبد. ولا أنا عابد ما عبدتم. ولا أنتم عابدون ما أعبد. لكم دينكم ولي دين. [SEP]',\n",
              "  'rank': 5,\n",
              "  'score': 0.042387232184410095}]"
            ]
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from random import randint\n",
        "compare_val_sample(randint(0,len(val_data)-1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWbNNkgD25FS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rnx0MIcxEAv",
        "outputId": "a6be9346-117f-468c-e050-b3cbf49db497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: ماهي الحيوانات التي ذكرت في القران ؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'حمر مستنفرة', 'rank': 1, 'score': 0.3215392827987671},\n",
              " {'answer': 'حمر مستنفرة. فرت من قسورة',\n",
              "  'rank': 2,\n",
              "  'score': 0.20909148454666138},\n",
              " {'answer': 'حمر مستن', 'rank': 3, 'score': 0.12875321507453918},\n",
              " {'answer': 'حمر', 'rank': 4, 'score': 0.12117047607898712},\n",
              " {'answer': 'حمر مستنفرة. فرت', 'rank': 5, 'score': 0.07084759324789047}]"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text =\"فما لهم عن التذكرة معرضين. كانهم حمر مستنفرة. فرت من قسورة \"\n",
        "q='ماهي الحيوانات التي ذكرت في القران ؟'\n",
        "quran_qa(text ,q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdZKoDN5yOjy",
        "outputId": "4b08c3d1-b2cb-4132-92f1-7a6e2c2a2fd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: ما جزاء المؤمنين الذي يبشر به القران ؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'لهم اجرا حسنا', 'rank': 1, 'score': 0.1304337978363037},\n",
              " {'answer': 'لهم اجرا حسنا.', 'rank': 2, 'score': 0.11242851614952087},\n",
              " {'answer': 'لهم اجرا حسنا. ماكثين فيه أبدا',\n",
              "  'rank': 3,\n",
              "  'score': 0.08264783024787903},\n",
              " {'answer': 'لهم اجرا حسنا. ماك', 'rank': 4, 'score': 0.07481755316257477},\n",
              " {'answer': 'ويبشر المؤمنين الذين يعملون الصالحات ان لهم اجرا حسنا',\n",
              "  'rank': 5,\n",
              "  'score': 0.05054086074233055}]"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text =\"الحمد لله الذي آنزل علي عبده الكتاب ولم يجعل له عوجا . قيما لينذر بأسا ششديدا من لدنه ويبشر المؤمنين الذين يعملون الصالحات ان لهم اجرا حسنا . ماكثين فيه أبدا .\"\n",
        "q=\"ما جزاء المؤمنين الذي يبشر به القران ؟\"\n",
        "quran_qa(text ,q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxNfBMG-s8GO",
        "outputId": "b0473194-9570-464f-aa0e-c3d192bfda62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: كم لبث اصحاب الكهف في الكهف ؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'ثلاث مائة سنين', 'rank': 1, 'score': 0.36915072798728943},\n",
              " {'answer': 'ولبثوا في كهفهم ثلاث مائة سنين',\n",
              "  'rank': 2,\n",
              "  'score': 0.1446506679058075},\n",
              " {'answer': 'ثلاث مائة', 'rank': 3, 'score': 0.08036283403635025},\n",
              " {'answer': 'ثلاث مائة سنين وازدادوا تسعا',\n",
              "  'rank': 4,\n",
              "  'score': 0.079884834587574},\n",
              " {'answer': 'مائة سنين', 'rank': 5, 'score': 0.054880786687135696}]"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text =\"ولا تقولن لشئ إني فاعل ذلك غدا إلا أن يشاء الله . واذكر ربك إذا نسيت وقل عسى أن يهديني ربي لأقرب من هذا رشدا . ولبثوا في كهفهم ثلاث مائة سنين وازدادوا تسعا قل الله أعلم بما لبثوا له غيب السماوات والأرض ابصر به واسمع مالهم من دونه من ولي ولا يشرك في حكمه احدا .\"\n",
        "q=\"كم لبث اصحاب الكهف في الكهف ؟\"\n",
        "quran_qa(text ,q, show_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFbNidqRue1c",
        "outputId": "6cc7a21a-3a55-41aa-b6c8-a170f6a674c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: في اي وقت حدث الاسراء ؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'سبحان الذي أسرى بعبده ليلا',\n",
              "  'rank': 1,\n",
              "  'score': 0.21491393446922302},\n",
              " {'answer': 'سبحان الذي أسرى بعبده ليلا من المسجد الحرام',\n",
              "  'rank': 2,\n",
              "  'score': 0.07977176457643509},\n",
              " {'answer': 'سبحان الذي أسرى بعبده ليلا من المسجد الحرام إلى المسجد الأقصى',\n",
              "  'rank': 3,\n",
              "  'score': 0.0636758953332901},\n",
              " {'answer': 'الذي أسرى بعبده ليلا', 'rank': 4, 'score': 0.056450020521879196},\n",
              " {'answer': 'سبحان الذي أسرى بعبده ليلا من المسجد الحرام إلى المسجد الأقصى الذي باركنا حوله لنريه من آياتنا',\n",
              "  'rank': 5,\n",
              "  'score': 0.044659193605184555}]"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text= 'سبحان الذي أسرى بعبده ليلا من المسجد الحرام إلى المسجد الأقصى الذي باركنا حوله لنريه من آياتنا إنه هو السميع البصير . واتينا موسى الكتاب وجعلناه هدى لبني إسرائيل أن لا تتخذوا من دوني وكيلا .'\n",
        "q='في اي وقت حدث الاسراء ؟'\n",
        "quran_qa(text ,q, show_all=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9J4lFK-IEya",
        "outputId": "a5af5d2d-322c-4d37-ad5a-ad22044d071b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: لماذا آسرى الله برسوله صلى الله عليه وسلم ؟\n",
            "top predicted answer:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'answer': 'لنريه من آياتنا', 'rank': 1, 'score': 0.399245947599411},\n",
              " {'answer': 'لنريه من آياتنا إنه', 'rank': 2, 'score': 0.1399897038936615},\n",
              " {'answer': 'لنريه من آياتنا إنه هو السميع البصير',\n",
              "  'rank': 3,\n",
              "  'score': 0.06484777480363846},\n",
              " {'answer': 'سبحان الذي أسرى بعبده ليلا من المسجد الحرام إلى المسجد الأقصى الذي باركنا حوله لنريه من آياتنا',\n",
              "  'rank': 4,\n",
              "  'score': 0.05865416303277016},\n",
              " {'answer': '##ريه من آياتنا', 'rank': 5, 'score': 0.02192697674036026}]"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text= 'سبحان الذي أسرى بعبده ليلا من المسجد الحرام إلى المسجد الأقصى الذي باركنا حوله لنريه من آياتنا إنه هو السميع البصير . واتينا موسى الكتاب وجعلناه هدى لبني إسرائيل أن لا تتخذوا من دوني وكيلا .'\n",
        "q='لماذا آسرى الله برسوله صلى الله عليه وسلم ؟'\n",
        "quran_qa(text ,q, show_all=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyEkpty7zUYM"
      },
      "source": [
        "## get submission file "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK7K0pKbzjIN",
        "outputId": "b653f56e-5622-48c8-d586-189f13b166ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['all3data2epoch20k.hd5']"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "filename = 'all3data2epoch20k.hd5'\n",
        "joblib.dump(model, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY2oeoO_zTvg"
      },
      "outputs": [],
      "source": [
        "result ={}\n",
        "for sample in val_data :\n",
        "  result[sample['pq_id']]=quran_qa(sample['passage'], sample['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EL954wkIXZF"
      },
      "outputs": [],
      "source": [
        "import json \n",
        "with open('star_run18.json', 'w' , encoding= 'utf8') as fp:\n",
        "  json.dump(result , fp, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNdZ_fFm_lzI"
      },
      "source": [
        "## Get scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdUfjwh79JfS",
        "outputId": "f656fe66-c021-49e9-cc1b-70b34110d27a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/drive/MyDrive/Deep Learning Projects/Quran_QA/Q_QA_task_original_code/quranqa/code/quranqa22_submission_checker.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python3 \"/content/drive/MyDrive/Deep Learning Projects/Quran_QA/Q_QA_task_original_code/quranqa/code/quranqa22_submission_checker.py\" --run_file \"/content/star_run08.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzwLUYlE_kAo",
        "outputId": "c144c36f-a290-4e43-9bac-850d77b39cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-03-28 11:40:28,190 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "Loaded 109 records from /content/drive/MyDrive/Quran_QA/Q_QA_task_original_code/quranqa/datasets/qrcd_v1.1_dev.jsonl\n",
            "The run file is correct.\n",
            "{\"pRR\": 0.5876249128383453, \"exact_match\": 0.3211009174311927, \"f1\": 0.5637567575874738}\n"
          ]
        }
      ],
      "source": [
        "!python3 \"/content/drive/MyDrive/Quran_QA/Q_QA_task_original_code/quranqa/code/quranqa22_eval.py\" --run_file \"/content/star_run18.json\" --gold_answers_file \"/content/drive/MyDrive/Quran_QA/Q_QA_task_original_code/quranqa/datasets/qrcd_v1.1_dev.jsonl\" "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"/content/drive/MyDrive/Quran_QA/models/quranBERTqa/checkpoint-1480/\""
      ],
      "metadata": {
        "id": "UjLfgivs8xRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9a_-hm7ZcPKQ",
        "HHpIDNZQsfJm"
      ],
      "name": "quran qa | apply to our data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}